{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image recognition using VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMUYu305KorDn7kbyMkWS9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bray2020/AI-works/blob/main/Image_recognition_using_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHv6I0KdYV6L"
      },
      "source": [
        "# Pancake and Waffle image recognition using Pre-trained Models:\n",
        "- Used pre-built Convolutional neural networks in Keras known as VGG16\n",
        "- VGG16 is trained on ImageNet dataset\n",
        "- It is able to recognize 1000 common world objects(which is 1000 class problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rapxqHymYoUe"
      },
      "source": [
        "# About pre-trained models:\n",
        "- From keras we can access them using applications module\n",
        "- The first time when we access these models, keras will download them on our machine and since these models can be fairly large, it will take some time for us to use these models the first time.\n",
        "- We will need to pre-process images in a particular manner when we use a particular model, keras makes it easy for us to do this, by using preprocess_input\n",
        "- Credit: https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nchlfYzg2yMN"
      },
      "source": [
        "# Specification for Input:\n",
        "- The network expects one or more images as input, that means the input array will need to be 4D (4-dimensional: samples, rows, columns, channels)\n",
        "- The default image shape that VGG16 has is = (224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_GWVWgNY2Wu"
      },
      "source": [
        "#import necessary libraries:\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import os\n",
        "import glob\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiCfnl8E2UM5"
      },
      "source": [
        "#### Step1: loading the model in the memory(if doing this for the first time then the model will download in the system and loaded in the memory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21-lXopBUmfC",
        "outputId": "33d24b12-bbd8-4c5d-fb2a-2f04607f943a"
      },
      "source": [
        "#Load the VGG Model\n",
        "model = VGG16()\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "553476096/553467096 [==============================] - 4s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZHd4TEMZAlQ"
      },
      "source": [
        "- As model summary shows the default image shape that VGG16 has is = (224, 224, 3)\n",
        "- In order to use this pre-trained  odel we need to fed compatible shaped data only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo5lCrG4tKLt"
      },
      "source": [
        "#### Step2: Load Image\n",
        "- Here used 2 sample images from waffle and pancake folder respectively:\n",
        "- Used the load_img() function to load the image and resize it to the required size of 224Ã—224 pixels with 3 channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd3A6y_HTKvx",
        "outputId": "aedf5063-9355-4210-86de-e79712695186"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD00NhA3jXTA"
      },
      "source": [
        "img_path1 = \"/content/drive/MyDrive/Colab Notebooks/Tensorflow/waffle_pancakes/train/waffles/images_q=tbn_ANd9GcQ0NS4Y3hWawXhmkSY0zLgqe27I0vGW-DwNWxYK4A_-Nca0Cz2mXg.png\"\n",
        "\n",
        "img_path2 = \"/content/drive/MyDrive/Colab Notebooks/Tensorflow/waffle_pancakes/train/pancakes/images_q=tbn_ANd9GcQ6NswsQ3xjdbfVfBGnAnAG1quZShGrRBq_XnFCZBHd-X2ed_uk.png\"\n",
        "\n",
        "img = load_img(img_path2,target_size=(224,224))   #used the pancake image for prediction"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhDBtdo3Yb8"
      },
      "source": [
        "#### Step3:Prepare Image to feed into the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnQoxz2cU0zc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19078c7d-0e4d-4271-d9f0-44b7fc206c3f"
      },
      "source": [
        "#check the size of the image now:\n",
        "img.size"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36dUnDwAj9gi",
        "outputId": "7650cc75-a7aa-4f09-9734-96b301692b8f"
      },
      "source": [
        "#Converted the 2D pixels to a 3D array so that we can work with it in Keras. Used the img_to_array() function for this\n",
        "img_array = img_to_array(img)\n",
        "img_array.shape    #3 rgb channels"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv1m37Ijj9iT",
        "outputId": "85e3ed43-91c5-4e06-fba4-88628149120b"
      },
      "source": [
        "#Increase the number of dimensions to 4 as we need the input as 4D array\n",
        "img_array= np.expand_dims(img_array,axis=0)  #it will do row-wise extension\n",
        "img_array.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkff3W7hlGKl"
      },
      "source": [
        "- So, now we have converted the image into a 4D array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcFZZIrV4XwR"
      },
      "source": [
        "#### Step5: Keras provides a function called preprocess_input() to prepare new input for the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4E0xqXkj9lO"
      },
      "source": [
        "img_pre_processed = preprocess_input(img_array)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWLI28S60rK_"
      },
      "source": [
        "- We are now ready to make a prediction for the prepared image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teA3mQW84jEi"
      },
      "source": [
        "#### Step6: Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knFp1YLrj9nd"
      },
      "source": [
        "preds = model.predict(img_pre_processed)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA4R3D5401i2"
      },
      "source": [
        "#### Step7: Interpret the prediction\n",
        "- Keras provides a function to interpret the probabilities called decode_predictions().\n",
        "- It can return a list of classes and their probabilities in case we would like to present the top n number of objects that may be in the predicted image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhZsxpR-j9sS",
        "outputId": "7519d3b5-94e6-4d02-edff-e015527e2542"
      },
      "source": [
        "from keras.applications.vgg16 import decode_predictions   #this funtion results into a list of tuples(class,description,probability) for top n(10 here) classes\n",
        "decode_predictions(preds, top=10)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n07614500', 'ice_cream', 0.56304026),\n",
              "  ('n02776631', 'bakery', 0.32920995),\n",
              "  ('n07836838', 'chocolate_sauce', 0.057538867),\n",
              "  ('n02948072', 'candle', 0.013039294),\n",
              "  ('n07613480', 'trifle', 0.0055008866),\n",
              "  ('n04522168', 'vase', 0.0043339455),\n",
              "  ('n07684084', 'French_loaf', 0.003922513),\n",
              "  ('n07860988', 'dough', 0.0028968817),\n",
              "  ('n07875152', 'potpie', 0.0027773778),\n",
              "  ('n07695742', 'pretzel', 0.0016934127)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h0J5wLloSi7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}